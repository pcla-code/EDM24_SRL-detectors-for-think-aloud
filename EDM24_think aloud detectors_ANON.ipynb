{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e6caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import openai\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, confusion_matrix, accuracy_score, f1_score, cohen_kappa_score\n",
    "from sklearn.model_selection import GroupKFold, train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn import tree, metrics\n",
    "import xgboost\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "random.seed(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e52037e",
   "metadata": {},
   "source": [
    "### import data and set up 5 folds cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d9ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df = pd.read_csv(\"think_aloud_all_platforms_2023Nov27.csv\") # this csv contains all valid input, in attempt level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ab5265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for CV\n",
    "\n",
    "group_dict = dict()\n",
    "groups = np.array([])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    s_id = row['anon_student_id']\n",
    "    if s_id not in group_dict:\n",
    "        group_dict[s_id] = index\n",
    "    groups = np.append(groups, group_dict[s_id])\n",
    "    \n",
    "# Set up the splitter with 5 splits\n",
    "gkf = GroupKFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5f4821",
   "metadata": {},
   "source": [
    "### USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c63913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load universal sentence encoder\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ee5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting text into embedding - USE\n",
    "text = np.array(df['utterance_combined'], dtype=object)[:, np.newaxis]\n",
    "\n",
    "X = []\n",
    "for r in tqdm(text):\n",
    "    emb = embed(r)\n",
    "    review_emb = tf.reshape(emb, [-1]).numpy()\n",
    "    X.append(review_emb)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b5883",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fed439b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load openAI key REMOVE when upload to github (TODO)\n",
    "openai.api_key = 'ADD YOUR KEY HERE' #api key\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e4161",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting text into embedding - OpenAI\n",
    "text = df['utterance_combined']\n",
    "\n",
    "X = []\n",
    "for r in tqdm(text):\n",
    "    emb = get_embedding(r)\n",
    "    review_emb = tf.reshape(emb, [-1]).numpy()\n",
    "    X.append(review_emb)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e8a8f9",
   "metadata": {},
   "source": [
    "### prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b188f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define label\n",
    "y = df.wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b71124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up storage arrays for each round of validation\n",
    "roc_auc_scores_all = np.array([])\n",
    "pred = pd.DataFrame()\n",
    "\n",
    "\n",
    "for train_index, test_index in gkf.split(X, y, groups=groups):\n",
    "    \n",
    "    # Get the training and test data from the dataset for this group\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(28, input_shape=(1536,), activation='relu')) \n",
    "    model.add(Dense(28, activation='relu')) \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer= optimizer,metrics = ['acc'])\n",
    "    \n",
    "    \n",
    "    num_epochs = 30\n",
    "    batch_size = 10\n",
    "\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        epochs=num_epochs, \n",
    "        validation_split=0.1,\n",
    "        shuffle=True, \n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    # test classifier on this round of testing group\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    pred_new = pd.concat([\n",
    "    pd.DataFrame(df.iloc[test_index,[0]]).reset_index(drop=True), #row number\n",
    "    pd.DataFrame(y.iloc[test_index]).reset_index(drop=True),\n",
    "    pd.DataFrame(predictions).reset_index(drop=True)],ignore_index=True, axis = 1)\n",
    "    \n",
    "    pred = pred.append(pred_new, ignore_index=True)\n",
    "    \n",
    "    # compute some metrics and store them for averaging later on\n",
    "   \n",
    "    # AUC\n",
    "    roc_auc_scores = roc_auc_score(y_test, predictions)\n",
    "    roc_auc_scores_all = np.append(roc_auc_scores_all, roc_auc_scores)\n",
    "    \n",
    "\n",
    "    \n",
    "# print mean scores for the 5-fold CV\n",
    "print(\"average roc_auc: \", np.round(roc_auc_scores_all.mean(), 3))\n",
    "print(\"stdv roc_auc: \", np.round(roc_auc_scores_all.std(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b072551",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_use = pd.concat(\n",
    "    [pd.DataFrame(pred_use_process),\n",
    "     pd.DataFrame(pred_use_plan),\n",
    "     pd.DataFrame(pred_use_act),\n",
    "     pd.DataFrame(pred_use_wrong),\n",
    "    ], axis=1)\n",
    "\n",
    "pred_use.to_csv(\"pred_use.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_openai_v3 = pd.concat(\n",
    "    [pd.DataFrame(pred_openai_process),\n",
    "     pd.DataFrame(pred_openai_plan),\n",
    "     pd.DataFrame(pred_openai_act),\n",
    "     pd.DataFrame(pred_openai_wrong),\n",
    "    ], axis=1)\n",
    "\n",
    "pred_openai_v3.to_csv(\"pred_openai_v3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c27d0ea",
   "metadata": {},
   "source": [
    "## Transferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e6b6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = df[df['platform'].isin(['ORCCA','Logic Tutor'])].index\n",
    "test_indices = df[df['platform'] == 'Stoich'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2d0f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.wrong\n",
    "\n",
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_train = y.iloc[train_indices]\n",
    "y_test = y.iloc[test_indices]\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(Dense(28, input_shape=(1536,), activation='relu')) \n",
    "model.add(Dense(28, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer= optimizer,metrics = ['acc'])\n",
    "    \n",
    "    \n",
    "num_epochs = 30\n",
    "batch_size = 10\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=num_epochs,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True, \n",
    "    batch_size=batch_size)\n",
    "\n",
    "# test classifier on this round of testing group\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(roc_auc_score(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
